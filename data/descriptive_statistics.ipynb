{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"training.json\"\n",
    "file_output = \"training_stats.csv\"\n",
    "data_name = \"training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"dev.json\"\n",
    "# file_output = \"dev_stats.csv\"\n",
    "# data_name = \"dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"test.json\"\n",
    "# file_output = \"test_stats.csv\"\n",
    "# data_name = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(file_name)\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = data['data']\n",
    "N = len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NUmber of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "810"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_set = set()\n",
    "for element in arr:\n",
    "    text_set.add(element[\"context\"])\n",
    "\n",
    "n_texts = len(text_set)\n",
    "final_dict[\"# of texts\"] = n_texts\n",
    "n_texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "835"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_questions = len(arr)\n",
    "final_dict[\"# of MCQs\"] = n_questions\n",
    "n_questions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One answer per choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_answers = np.zeros(N)\n",
    "for idx, element in enumerate(arr):\n",
    "    choices = element[\"choices\"]\n",
    "    n_ans = 0  \n",
    "    for choice in choices:\n",
    "        if choice[\"type\"] == \"correct answer\":\n",
    "            n_ans +=1\n",
    "    n_answers[idx] = n_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in n_answers:\n",
    "    assert element == 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_distractors = np.zeros(N)\n",
    "for idx, element in enumerate(arr):\n",
    "    choices = element[\"choices\"]\n",
    "    n_dist = 0 \n",
    "    for choice in choices:\n",
    "        if choice[\"type\"] == \"distractor\":\n",
    "            n_dist +=1\n",
    "    assert n_dist < 5\n",
    "    n_distractors[idx] = n_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 4., 4., 2., 3., 3., 4., 4., 3., 2., 2., 2., 2., 2., 4., 4.,\n",
       "       4., 3., 4., 4., 3., 3., 4., 2., 3., 4., 3., 3., 2., 4., 4., 3., 4.,\n",
       "       3., 2., 2., 4., 3., 4., 3., 4., 3., 3., 4., 4., 4., 3., 3., 4., 3.,\n",
       "       3., 4., 4., 3., 3., 4., 4., 4., 4., 3., 2., 2., 3., 3., 3., 3., 4.,\n",
       "       4., 3., 2., 3., 4., 2., 3., 3., 4., 3., 3., 4., 4., 4., 2., 3., 4.,\n",
       "       4., 3., 3., 3., 3., 2., 4., 3., 4., 3., 3., 3., 2., 4., 3., 4., 3.,\n",
       "       3., 4., 4., 3., 2., 3., 3., 4., 4., 3., 2., 2., 4., 4., 2., 4., 2.,\n",
       "       3., 3., 4., 3., 3., 2., 3., 3., 4., 3., 3., 3., 3., 2., 3., 4., 3.,\n",
       "       3., 2., 2., 3., 4., 2., 4., 2., 3., 3., 4., 2., 2., 3., 4., 4., 3.,\n",
       "       4., 3., 4., 2., 4., 3., 4., 3., 3., 2., 3., 3., 4., 2., 4., 4., 2.,\n",
       "       3., 4., 3., 4., 3., 4., 3., 4., 3., 3., 4., 3., 3., 2., 3., 3., 3.,\n",
       "       4., 4., 3., 4., 4., 2., 3., 2., 3., 3., 4., 3., 4., 3., 3., 3., 3.,\n",
       "       3., 2., 3., 2., 3., 3., 4., 4., 4., 4., 3., 3., 2., 4., 4., 2., 3.,\n",
       "       4., 4., 4., 3., 3., 2., 3., 3., 4., 3., 4., 3., 3., 3., 4., 3., 3.,\n",
       "       2., 2., 4., 2., 4., 4., 3., 3., 2., 4., 2., 4., 4., 3., 3., 4., 4.,\n",
       "       3., 4., 4., 2., 3., 2., 3., 3., 4., 4., 4., 4., 4., 3., 3., 3., 3.,\n",
       "       3., 4., 4., 3., 4., 4., 3., 4., 4., 4., 4., 2., 4., 4., 3., 4., 4.,\n",
       "       3., 3., 4., 2., 3., 4., 3., 4., 3., 3., 2., 2., 4., 4., 4., 3., 3.,\n",
       "       3., 4., 3., 3., 3., 3., 3., 3., 3., 4., 3., 4., 2., 3., 4., 4., 4.,\n",
       "       4., 4., 3., 4., 3., 3., 4., 2., 2., 4., 2., 3., 4., 3., 4., 3., 3.,\n",
       "       2., 2., 4., 3., 3., 3., 4., 3., 3., 3., 2., 2., 3., 4., 4., 3., 4.,\n",
       "       4., 3., 4., 3., 4., 2., 4., 3., 2., 4., 4., 3., 2., 3., 4., 4., 4.,\n",
       "       3., 4., 3., 2., 3., 3., 4., 3., 2., 3., 2., 3., 2., 3., 2., 3., 4.,\n",
       "       3., 4., 4., 2., 4., 4., 3., 4., 4., 4., 4., 4., 4., 3., 3., 2., 2.,\n",
       "       4., 2., 2., 3., 3., 3., 3., 4., 4., 2., 3., 3., 3., 2., 2., 4., 3.,\n",
       "       4., 3., 2., 3., 2., 4., 4., 4., 4., 3., 4., 2., 2., 3., 2., 3., 4.,\n",
       "       3., 3., 2., 3., 4., 3., 4., 3., 2., 3., 3., 4., 3., 4., 2., 2., 3.,\n",
       "       4., 3., 3., 3., 3., 4., 4., 2., 3., 3., 3., 3., 3., 4., 3., 3., 3.,\n",
       "       2., 3., 4., 2., 3., 2., 2., 4., 4., 3., 4., 3., 2., 4., 3., 2., 3.,\n",
       "       2., 3., 3., 3., 3., 3., 2., 2., 2., 3., 3., 2., 4., 3., 2., 3., 3.,\n",
       "       3., 2., 3., 2., 3., 3., 3., 4., 3., 4., 4., 3., 3., 3., 4., 3., 3.,\n",
       "       4., 4., 2., 3., 4., 3., 4., 4., 4., 3., 2., 2., 3., 3., 2., 2., 2.,\n",
       "       4., 4., 4., 3., 3., 4., 3., 4., 3., 2., 3., 4., 3., 4., 3., 4., 4.,\n",
       "       2., 4., 3., 3., 2., 2., 3., 4., 4., 2., 4., 3., 3., 3., 2., 3., 4.,\n",
       "       4., 4., 3., 3., 4., 2., 3., 4., 3., 4., 3., 2., 2., 3., 2., 2., 2.,\n",
       "       2., 3., 3., 4., 3., 2., 4., 4., 3., 4., 4., 4., 4., 3., 4., 4., 3.,\n",
       "       3., 2., 2., 2., 4., 2., 4., 3., 3., 4., 4., 3., 2., 4., 3., 2., 3.,\n",
       "       4., 2., 4., 3., 3., 4., 3., 2., 3., 4., 3., 4., 4., 3., 2., 2., 4.,\n",
       "       4., 3., 3., 2., 4., 4., 2., 4., 4., 2., 3., 3., 4., 4., 3., 4., 2.,\n",
       "       3., 3., 3., 3., 3., 3., 3., 4., 2., 4., 3., 4., 4., 4., 2., 2., 2.,\n",
       "       3., 3., 4., 3., 4., 2., 3., 3., 4., 4., 4., 4., 4., 4., 3., 4., 3.,\n",
       "       4., 2., 3., 3., 2., 4., 4., 3., 3., 2., 2., 4., 2., 2., 3., 3., 3.,\n",
       "       4., 4., 3., 3., 2., 4., 2., 3., 4., 3., 3., 2., 4., 4., 3., 2., 3.,\n",
       "       3., 4., 3., 4., 3., 3., 4., 4., 2., 4., 4., 4., 4., 2., 2., 4., 4.,\n",
       "       3., 3., 3., 3., 4., 3., 3., 4., 3., 2., 4., 2., 4., 2., 3., 4., 3.,\n",
       "       4., 3., 4., 3., 4., 2., 3., 3., 4., 3., 4., 4., 3., 4., 3., 4., 2.,\n",
       "       3., 2., 4., 3., 3., 2., 3., 4., 4., 4., 3., 3., 4., 4., 3., 4., 4.,\n",
       "       3., 3., 3., 3., 3., 3., 4., 2., 2., 3., 4., 3., 3., 3., 4., 3., 2.,\n",
       "       3., 4., 3., 3., 2., 3., 3., 4., 4., 4., 4., 3., 2., 2., 3., 2., 2.,\n",
       "       2., 3.])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dist_mean = np.mean(n_distractors)\n",
    "n_dist_std = np.std(n_distractors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1592814371257485\n",
      "0.7372188950618791\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.16 +- 0.74'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(n_dist_mean)\n",
    "print(n_dist_std)\n",
    "final_dict[\"# of D\"] = f\"{n_dist_mean:0.2f} +- {n_dist_std:0.2f}\"\n",
    "final_dict[\"# of D\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(_string):\n",
    "    arr = _string.split(\" \")\n",
    "    return len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 94., 171., 102., 159., 154., 109., 237., 211., 302., 182.,  90.,\n",
       "       112., 152., 247., 105., 123.,  48., 140., 271., 271., 105., 195.,\n",
       "       170., 124., 165., 162., 169., 106., 150.,  90., 123., 197., 127.,\n",
       "       159.,  92., 132.,  61., 206., 136., 114., 174., 219., 177., 108.,\n",
       "       218., 218., 149., 158., 102., 213., 152., 247., 158., 123.,  82.,\n",
       "       107., 165., 178., 122., 157., 172.,  79.,  96., 186., 176., 129.,\n",
       "       182., 200., 127., 127.,  92., 138., 224., 165., 122.,  87., 211.,\n",
       "       122.,  89., 112., 142., 175.,  93.,  92., 146., 235., 154., 216.,\n",
       "       204., 179., 130., 102., 268., 268., 116., 116., 159., 113.,  87.,\n",
       "       185., 185., 185., 106., 187., 123., 114.,  90., 124., 120., 157.,\n",
       "       215., 118., 124., 139., 134., 181., 119.,  84., 126., 248., 127.,\n",
       "       237., 167., 141., 120., 150., 170., 143., 182., 136., 244., 195.,\n",
       "       120., 157., 111., 174., 200., 119., 169., 134., 305., 146., 283.,\n",
       "        92., 194., 453., 213., 142.,  93.,  93., 240., 240., 117., 220.,\n",
       "       233., 119., 112.,  96., 174., 143., 159., 160., 144., 110., 182.,\n",
       "       142., 200., 147., 203., 115., 141., 141., 164., 130., 230., 106.,\n",
       "       148., 105., 103., 121.,  98.,  94., 248., 204., 210., 118.,  89.,\n",
       "       222., 132., 120., 212., 150., 140., 136., 109., 197., 159.,  93.,\n",
       "       289., 332.,  95., 165., 186.,  74.,  93., 149., 198., 232.,  74.,\n",
       "       161., 161., 137., 148., 242., 139., 218., 199., 291., 130., 139.,\n",
       "        67., 236., 149.,  93., 168., 164., 146., 116., 103., 139., 168.,\n",
       "       117., 125., 138., 211., 211., 120., 128., 102., 172., 216., 106.,\n",
       "       144.,  72., 232., 158., 150., 105., 107., 215., 125., 177., 186.,\n",
       "       125., 131., 117., 189., 209., 186., 205., 151., 196., 115., 136.,\n",
       "       289., 100., 195.,  99., 151., 150., 120.,  87., 166., 141., 176.,\n",
       "       153., 159., 159., 244., 140., 127., 282., 154., 126.,  95., 291.,\n",
       "       169., 140., 180., 126., 104., 118., 158., 111., 203., 218., 238.,\n",
       "       119., 132., 175.,  58.,  83., 168., 144., 252., 193., 193., 217.,\n",
       "        72., 178.,  60., 151., 148., 148., 116., 143., 155., 118., 127.,\n",
       "       167., 189., 275., 128., 149., 103., 103., 170., 183., 106., 225.,\n",
       "       169., 172., 153., 153., 173., 240., 127., 203., 106., 215., 135.,\n",
       "        98., 251.,  91., 113., 124., 132., 164., 253., 128., 335., 214.,\n",
       "       110., 109., 134., 224., 130., 157., 110., 141., 104., 290., 143.,\n",
       "       143., 104., 159., 100., 109., 134., 109., 227., 159., 127., 115.,\n",
       "       237., 232., 157., 179., 107., 252., 181., 265., 354., 190., 157.,\n",
       "       280.,  98., 168., 108., 139., 182., 181., 272., 189., 132., 187.,\n",
       "       201., 113., 207., 249., 119., 159., 122., 132., 260., 188., 147.,\n",
       "       302., 155., 137., 120., 239., 101., 134., 163.,  76., 113., 131.,\n",
       "       151.,  98., 122., 123., 118., 184., 117., 106., 111., 106.,  84.,\n",
       "       211., 199., 168., 102., 102., 170., 184., 197., 111., 163., 184.,\n",
       "       123., 228., 161., 125., 117., 117., 206., 170.,  95., 167., 171.,\n",
       "       177., 100., 134., 134., 219., 110., 170., 110., 113., 187.,  66.,\n",
       "       248., 105., 126., 175., 167., 203.,  95., 132., 125., 104., 266.,\n",
       "       116., 162., 126., 139., 166., 279.,  90., 186., 166., 116., 148.,\n",
       "       402., 152., 128., 166., 123., 237., 111., 141., 177., 120., 151.,\n",
       "       232., 118., 230., 192., 126., 111., 121., 199., 155., 101.,  66.,\n",
       "       230., 225.,  98., 136., 176.,  95.,  81.,  89., 150.,  98., 119.,\n",
       "       292., 272., 132., 155., 186., 157., 234., 228., 151., 119., 172.,\n",
       "        97., 127.,  95., 145., 195., 123., 150., 205., 189.,  96., 159.,\n",
       "       190., 190.,  99.,  97., 107., 267.,  99., 249.,  96., 241., 101.,\n",
       "       116., 167.,  74., 149.,  83., 130., 126.,  67., 100., 149., 178.,\n",
       "        94., 171., 120., 275., 101., 116., 257., 165., 182., 115., 163.,\n",
       "       142., 242., 146., 112., 254., 176., 247., 176., 125., 112., 216.,\n",
       "       127., 148., 123.,  93., 136., 145., 167., 127., 111., 146., 130.,\n",
       "       112., 202., 120., 178., 178., 120., 120., 129.,  97., 183.,  93.,\n",
       "       102., 166., 359., 289., 101., 154., 148., 188., 169., 133., 198.,\n",
       "       228., 144., 181., 222., 106., 161., 124., 155., 106., 259., 182.,\n",
       "        88., 141., 108., 184., 108., 131., 158., 145., 124., 144., 193.,\n",
       "       140., 131., 133., 140., 317., 132., 139., 198., 183., 152., 191.,\n",
       "       153., 167.,  94., 119., 178., 121., 212.,  89., 261., 117., 162.,\n",
       "       162., 181., 130., 138., 175., 118., 170., 199., 162., 175., 197.,\n",
       "       137., 161., 181., 203., 206., 175., 229., 125., 145., 110., 129.,\n",
       "       126., 158., 161., 249., 137., 113., 143., 333., 131.,  98., 145.,\n",
       "       211., 127., 110., 102., 155.,  98., 122.,  82., 152., 305., 198.,\n",
       "       181., 171., 127., 104., 112., 109., 128., 174., 104., 178., 218.,\n",
       "       218., 209., 158., 161., 169., 169., 184., 214., 151., 244., 136.,\n",
       "       136., 271., 180., 104., 115., 188., 138., 159., 299., 282., 334.,\n",
       "       182., 118., 118., 128., 162., 122., 227., 235., 159., 119., 167.,\n",
       "       121., 136., 153., 112.,  84., 229., 123., 210., 132., 154., 207.,\n",
       "       100., 117., 153., 192., 118., 130., 161., 201., 155., 156., 158.,\n",
       "       153., 132., 186.,  87., 316., 219., 222., 152., 139., 205., 113.,\n",
       "        98., 142.,  97., 204., 221., 160., 158., 113., 298., 298., 207.,\n",
       "       313., 143., 243., 157., 117., 142., 108.,  88.,  79.,  89., 223.,\n",
       "       119., 339., 139., 147., 123., 161., 244., 159., 121., 172., 137.,\n",
       "       125., 131., 155., 270., 270., 157., 128., 177., 115., 108., 135.,\n",
       "       149.,  85., 128., 189., 216., 213., 122., 124., 104., 141.])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_texts = np.zeros(N)\n",
    "for idx, element in enumerate(arr):\n",
    "    context = element[\"context\"]\n",
    "    len_texts[idx] = count_words(context)\n",
    "\n",
    "len_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453.0"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_text = np.max(len_texts)\n",
    "max_length_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158.2059880239521\n",
      "54.85740437208974\n"
     ]
    }
   ],
   "source": [
    "text_mean = np.mean(len_texts)\n",
    "text_std = np.std(len_texts)\n",
    "print(text_mean)\n",
    "print(text_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'158.21 +- 54.86'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict[\"Len(Text)\"] = f\"{text_mean:0.2f} +- {text_std:0.2f}\"\n",
    "final_dict[\"Max(Text)\"] = max_length_text\n",
    "final_dict[\"Len(Text)\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length of answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  1.,  2.,  1.,  1., 19., 13.,  2.,  1.,  3.,  1.,  1.,\n",
       "        8.,  1.,  2.,  3.,  1.,  1., 21.,  2.,  2.,  8.,  1.,  6.,  5.,\n",
       "        2.,  1.,  2.,  2.,  2.,  2.,  3.,  3.,  2., 14.,  1.,  3.,  1.,\n",
       "        2., 13., 10.,  1.,  3.,  1.,  1.,  2.,  1.,  2.,  1.,  4.,  4.,\n",
       "        1.,  2.,  1.,  4.,  1.,  4.,  1., 19.,  3.,  2.,  2., 10., 15.,\n",
       "        1., 10.,  4.,  2.,  1.,  1.,  1.,  2., 17.,  4., 16., 15.,  4.,\n",
       "        1.,  1.,  2.,  3.,  2.,  2.,  4.,  4.,  1.,  2.,  9.,  8., 10.,\n",
       "        1., 14.,  1.,  6.,  3.,  6.,  1.,  1.,  2.,  2.,  5.,  4.,  1.,\n",
       "        1.,  2.,  2.,  1.,  1.,  1., 13.,  9.,  1.,  1.,  3.,  2.,  3.,\n",
       "        1.,  4.,  8.,  2.,  2.,  5.,  9.,  6.,  1.,  3.,  2., 19.,  2.,\n",
       "        1., 16.,  1.,  1.,  2., 13., 11.,  2.,  1.,  1.,  8., 18.,  1.,\n",
       "        1.,  8., 15., 21.,  4.,  2., 13.,  6.,  4.,  1.,  4.,  3.,  1.,\n",
       "        3.,  3.,  5.,  3.,  5., 13., 10.,  2.,  7.,  2., 10.,  1.,  1.,\n",
       "        1.,  1.,  1.,  2.,  3., 16.,  1.,  4.,  1.,  2.,  1.,  2.,  3.,\n",
       "        1., 18., 13.,  3.,  2.,  3.,  2.,  3.,  2.,  1.,  1.,  1.,  4.,\n",
       "        4.,  1.,  1.,  1.,  1.,  5., 10., 12.,  4.,  1., 16.,  7.,  9.,\n",
       "        5.,  7., 14., 11.,  4.,  3.,  1.,  3.,  2., 11.,  1., 14.,  1.,\n",
       "        7.,  1.,  3., 19.,  1.,  3.,  1.,  1.,  1., 12.,  4.,  2.,  1.,\n",
       "        4.,  7.,  5.,  3.,  2.,  6.,  6.,  1.,  3.,  1.,  5.,  1.,  2.,\n",
       "        1.,  4.,  6.,  5.,  7.,  2.,  3.,  1.,  4., 11.,  3.,  1.,  2.,\n",
       "       13.,  1.,  3.,  1.,  7.,  1.,  6.,  2., 14.,  7.,  1.,  1.,  6.,\n",
       "       10.,  6.,  1.,  1.,  1.,  4.,  2.,  2., 13.,  2.,  8.,  3.,  8.,\n",
       "        1.,  1.,  8.,  1.,  1.,  1.,  3.,  2.,  4.,  9.,  9.,  4.,  6.,\n",
       "       10.,  1.,  1.,  6.,  3., 18.,  9.,  1.,  2.,  1.,  4.,  1.,  6.,\n",
       "        1.,  1.,  4.,  9.,  4.,  1.,  2.,  5.,  3.,  3.,  1., 17.,  4.,\n",
       "        1.,  9.,  4.,  1.,  3.,  2.,  1.,  6.,  1., 21.,  4.,  3., 14.,\n",
       "        1., 21.,  1.,  2.,  6.,  1., 11.,  1.,  1.,  2., 13.,  1., 11.,\n",
       "       17.,  1.,  1.,  3.,  8.,  4.,  5.,  3.,  2.,  3.,  7., 12.,  1.,\n",
       "        2.,  1.,  1.,  2.,  1., 11.,  2.,  1.,  1.,  1., 12.,  1.,  4.,\n",
       "       17.,  2.,  8.,  4.,  5.,  3.,  6.,  2., 10.,  4., 15.,  3.,  4.,\n",
       "        5.,  4.,  7.,  2.,  4.,  1.,  3.,  1.,  1.,  2.,  1.,  4.,  2.,\n",
       "        2.,  6.,  3.,  1., 12.,  4.,  2.,  1.,  1.,  1.,  3.,  4.,  1.,\n",
       "        2.,  2.,  2.,  2.,  1.,  2.,  4.,  3., 22.,  2.,  1.,  1.,  1.,\n",
       "        1.,  2.,  6.,  3.,  3.,  2.,  2.,  1.,  6., 10.,  1.,  5.,  1.,\n",
       "        4.,  2.,  3.,  1.,  4.,  5.,  1.,  3.,  1.,  1.,  1.,  1., 15.,\n",
       "        3.,  1.,  6.,  2.,  1.,  6.,  1., 11.,  2.,  2.,  2.,  4.,  1.,\n",
       "        1.,  8.,  4.,  2., 13.,  1.,  3., 12.,  2.,  9.,  5.,  2.,  4.,\n",
       "        1.,  2.,  4., 10.,  1.,  1.,  1.,  4., 11.,  3.,  7.,  4., 13.,\n",
       "        7., 10.,  4., 18., 11.,  1.,  6.,  2.,  5.,  4.,  4.,  1.,  8.,\n",
       "        9.,  1.,  1.,  6.,  2.,  1.,  1.,  2.,  1.,  2.,  3., 15.,  2.,\n",
       "        2.,  5.,  3., 11.,  2.,  1.,  1.,  6.,  7.,  9.,  8.,  3.,  1.,\n",
       "        2.,  2.,  3., 12.,  4., 13.,  7.,  3.,  4.,  2.,  4.,  3.,  3.,\n",
       "       13.,  1.,  1.,  1.,  1.,  3.,  1., 11.,  2.,  3.,  1.,  1.,  6.,\n",
       "        2.,  1.,  1.,  2.,  1., 11., 10.,  1.,  1.,  2.,  7.,  3., 11.,\n",
       "        3.,  4.,  5.,  1.,  2.,  3., 13.,  3.,  6.,  1.,  1.,  1., 16.,\n",
       "        1.,  2., 10.,  2.,  5.,  4.,  5.,  2.,  2.,  5., 19.,  2.,  3.,\n",
       "        3.,  2.,  1.,  4.,  2., 13.,  8.,  1.,  6.,  2.,  9.,  1.,  1.,\n",
       "        6., 14.,  1.,  1.,  2.,  3., 15.,  1., 13.,  1.,  2.,  2.,  2.,\n",
       "        4.,  2.,  2.,  1.,  3.,  4.,  6.,  1.,  1.,  3.,  4.,  1.,  7.,\n",
       "        2.,  1., 19.,  2.,  7.,  6., 14.,  7.,  5.,  2.,  3.,  1., 15.,\n",
       "        2.,  2.,  1.,  2.,  1., 13.,  4.,  6.,  2.,  1.,  3.,  1.,  1.,\n",
       "        4.,  1.,  1.,  5.,  1.,  4.,  3.,  3.,  1.,  4., 26.,  2.,  1.,\n",
       "        3.,  3.,  1.,  6., 18.,  1.,  1.,  9.,  2.,  5.,  2.,  2.,  1.,\n",
       "       15.,  4.,  1.,  3.,  5.,  2.,  1.,  1.,  1.,  2.,  1.,  3.,  2.,\n",
       "        2.,  7.,  4., 13.,  1.,  3.,  3.,  4.,  1.,  4.,  1.,  1.,  1.,\n",
       "        1.,  7.,  3.,  1.,  1.,  2.,  8., 13.,  7., 12.,  9., 14., 15.,\n",
       "       25.,  2.,  1., 16.,  2.,  2.,  1.,  2., 16.,  1.,  5.,  3.,  4.,\n",
       "        3.,  7.,  2.,  6.,  1.,  1.,  2.,  2.,  1.,  2.,  2.,  4.,  1.,\n",
       "        1.,  2., 10.,  1.,  5.,  1.,  2.,  1.,  4.,  1.,  1.,  1., 10.,\n",
       "        2.,  3.,  1.,  1.,  2.,  5.,  1.,  3.,  3.,  6.,  1.,  6.,  2.,\n",
       "        2.,  5.,  2.,  1.,  1., 15.,  3.,  3.,  9., 19.,  2.,  7.,  1.,\n",
       "       13.,  3.,  6.,  3.,  1.,  1.,  4.,  8.,  1.,  5.,  1.,  7.,  3.,\n",
       "        1.,  1.,  5.,  2.,  4.,  5.,  7.,  1.,  1.,  7.,  1.,  5.,  2.,\n",
       "        7., 10., 20.,  9.,  3.,  8.,  2.,  3.,  4.,  1., 12.,  6.,  1.,\n",
       "        1.,  3.,  1.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_answers = np.zeros(N)\n",
    "for idx, element in enumerate(arr):\n",
    "    choices = element[\"choices\"]\n",
    "    for choice in choices:\n",
    "        if choice[\"type\"] == \"correct answer\":\n",
    "            ans = choice[\"text\"]\n",
    "            len_answers[idx] = count_words(ans)\n",
    "\n",
    "len_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_ans = np.max(len_answers)\n",
    "max_length_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.355688622754491\n",
      "4.49075703832836\n"
     ]
    }
   ],
   "source": [
    "ans_mean = np.mean(len_answers)\n",
    "ans_std = np.std(len_answers)\n",
    "print(ans_mean)\n",
    "print(ans_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.36 +- 4.49'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict[\"Len(A)\"] = f\"{ans_mean:0.2f} +- {ans_std:0.2f}\"\n",
    "final_dict[\"Max(A)\"] = max_length_ans\n",
    "final_dict[\"Len(A)\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Length of distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 2, 1])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_distractors = []\n",
    "for idx, element in enumerate(arr):\n",
    "    choices = element[\"choices\"]\n",
    "    for choice in choices:\n",
    "        if choice[\"type\"] == \"distractor\":\n",
    "            dist = choice[\"text\"]\n",
    "            len_distractors.append(count_words(dist))\n",
    "\n",
    "len_distractors = np.array(len_distractors)\n",
    "len_distractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_dist = np.max(len_distractors)\n",
    "max_length_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.59325246398787\n",
      "4.969373979282124\n"
     ]
    }
   ],
   "source": [
    "dist_mean = np.mean(len_distractors)\n",
    "dist_std = np.std(len_distractors)\n",
    "print(dist_mean)\n",
    "print(dist_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.59 +- 4.97'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict[\"Len(D)\"] = f\"{dist_mean:0.2f} +- {dist_std:0.2f}\"\n",
    "final_dict[\"Max(D)\"] = max_length_dist\n",
    "final_dict[\"Len(D)\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diference ans and Dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.        ,  2.5       ,  1.        ,  0.        ,\n",
       "        1.        ,  8.        ,  5.25      ,  0.75      ,  0.        ,\n",
       "        0.        ,  0.        ,  0.        ,  3.5       ,  0.        ,\n",
       "        1.        ,  1.25      ,  0.        ,  0.        ,  6.5       ,\n",
       "        0.5       ,  1.        ,  9.        ,  0.        ,  0.5       ,\n",
       "        8.33333333,  2.75      ,  0.66666667,  1.        ,  0.        ,\n",
       "        1.75      ,  1.        ,  0.        ,  2.75      ,  1.66666667,\n",
       "        2.        ,  0.        ,  0.75      ,  0.        ,  0.75      ,\n",
       "        7.        ,  3.25      ,  0.        ,  1.33333333,  0.25      ,\n",
       "        0.5       ,  0.75      ,  0.        ,  1.        ,  0.        ,\n",
       "        1.33333333,  1.        ,  1.25      ,  0.75      ,  0.        ,\n",
       "        2.        ,  0.        ,  2.        ,  0.75      ,  5.25      ,\n",
       "        1.        ,  1.5       ,  0.        ,  6.33333333,  3.        ,\n",
       "        0.        ,  2.33333333,  4.        ,  0.25      ,  0.33333333,\n",
       "        0.        ,  1.66666667,  0.25      ,  5.5       ,  0.        ,\n",
       "        2.        ,  8.        ,  0.        ,  0.        ,  0.5       ,\n",
       "        0.5       ,  2.        ,  1.        ,  0.        ,  1.        ,\n",
       "        2.75      ,  0.        ,  1.        , 11.66666667,  4.66666667,\n",
       "        2.        ,  0.25      ,  3.        ,  0.        ,  4.        ,\n",
       "        2.66666667,  2.        ,  0.5       ,  0.75      ,  0.33333333,\n",
       "        0.5       ,  6.33333333,  6.        ,  0.        ,  0.        ,\n",
       "        0.66666667,  0.        ,  0.        ,  0.        ,  0.25      ,\n",
       "        2.75      ,  2.33333333,  0.        ,  0.        ,  1.25      ,\n",
       "        1.        ,  0.        ,  0.        ,  1.        ,  1.66666667,\n",
       "        0.33333333,  0.        ,  6.33333333, 10.        ,  0.        ,\n",
       "        0.        ,  0.        ,  1.        ,  5.        ,  0.66666667,\n",
       "        0.        ,  6.33333333,  0.        ,  0.66666667,  0.25      ,\n",
       "        2.66666667,  6.        ,  0.        ,  0.        ,  0.        ,\n",
       "        3.75      ,  0.5       ,  0.5       ,  0.5       ,  5.        ,\n",
       "       13.        ,  9.75      ,  0.5       ,  0.        ,  6.66666667,\n",
       "        1.        ,  1.        ,  0.        ,  0.5       ,  1.66666667,\n",
       "        0.        ,  1.5       ,  0.75      ,  8.33333333,  2.        ,\n",
       "        2.33333333,  4.66666667,  8.5       ,  1.        ,  3.66666667,\n",
       "        0.5       , 10.5       ,  0.        ,  0.        ,  0.5       ,\n",
       "        0.        ,  0.        ,  0.        ,  0.5       ,  5.33333333,\n",
       "        0.25      ,  1.66666667,  0.        ,  1.        ,  2.        ,\n",
       "        2.        ,  0.66666667,  0.        ,  7.        ,  5.        ,\n",
       "        1.66666667,  0.        ,  0.5       ,  0.        ,  0.66666667,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  0.5       ,\n",
       "        9.33333333,  2.33333333,  0.        ,  0.        ,  0.75      ,\n",
       "        1.33333333,  5.        ,  4.        ,  3.        ,  0.        ,\n",
       "        7.5       ,  2.33333333,  4.        ,  2.33333333,  3.33333333,\n",
       "        5.75      ,  2.5       ,  1.        ,  1.75      ,  0.33333333,\n",
       "        0.        ,  0.        , 13.5       ,  0.        , 12.5       ,\n",
       "        0.        ,  3.25      ,  0.75      ,  1.        ,  5.66666667,\n",
       "        0.        ,  1.        ,  0.        ,  1.        ,  0.        ,\n",
       "        7.33333333,  1.5       ,  4.33333333,  0.66666667,  3.66666667,\n",
       "        3.25      ,  0.66666667,  0.66666667,  0.5       ,  0.        ,\n",
       "        2.5       ,  0.        ,  1.        ,  0.5       ,  5.66666667,\n",
       "        0.        ,  0.        ,  0.        ,  1.        ,  6.        ,\n",
       "        1.5       ,  3.33333333,  0.66666667,  1.5       ,  0.5       ,\n",
       "        1.33333333,  5.25      ,  0.5       ,  0.        ,  0.        ,\n",
       "        1.5       ,  0.        ,  2.        ,  0.        ,  5.        ,\n",
       "        0.        ,  2.        ,  0.5       ,  3.33333333,  2.        ,\n",
       "        0.        ,  0.        ,  2.33333333,  5.        ,  4.        ,\n",
       "        0.        ,  0.        ,  0.        ,  1.33333333,  0.25      ,\n",
       "        0.5       ,  4.25      ,  1.        ,  3.5       ,  0.75      ,\n",
       "        2.75      ,  0.        ,  0.        ,  3.25      ,  0.        ,\n",
       "        0.66666667,  0.75      ,  1.        ,  0.        ,  4.25      ,\n",
       "        2.        ,  2.        ,  3.        ,  2.33333333,  7.        ,\n",
       "        0.        ,  0.        ,  2.        ,  1.5       ,  7.        ,\n",
       "        2.33333333,  0.        ,  1.        ,  1.        ,  8.66666667,\n",
       "        0.33333333,  3.        ,  0.        ,  0.        ,  1.33333333,\n",
       "        3.        ,  1.33333333,  0.25      ,  0.        ,  1.        ,\n",
       "        1.75      ,  1.25      ,  0.        ,  7.25      ,  2.25      ,\n",
       "        0.        ,  3.5       ,  0.        ,  0.        ,  3.5       ,\n",
       "        0.        ,  0.        ,  2.        ,  0.        ,  4.        ,\n",
       "        0.75      ,  0.66666667,  4.75      ,  0.        ,  3.        ,\n",
       "        0.5       ,  0.5       ,  2.75      ,  0.        ,  4.66666667,\n",
       "        0.        ,  1.25      ,  0.        , 10.33333333,  0.        ,\n",
       "        2.5       ,  4.        ,  0.        ,  0.5       ,  0.5       ,\n",
       "        4.33333333,  1.25      ,  1.75      ,  2.66666667,  0.        ,\n",
       "        1.33333333,  3.        ,  5.        ,  0.        ,  0.        ,\n",
       "        0.        ,  1.5       ,  1.        ,  0.33333333,  3.        ,\n",
       "        0.33333333,  0.        ,  0.        ,  0.25      ,  3.33333333,\n",
       "        0.        ,  3.33333333,  2.        ,  1.        ,  5.33333333,\n",
       "        1.5       ,  1.33333333,  0.        ,  0.        ,  0.        ,\n",
       "        4.        ,  2.        ,  3.        ,  0.        ,  1.66666667,\n",
       "        1.        ,  1.66666667,  4.        ,  1.        ,  2.        ,\n",
       "        0.        ,  0.25      ,  2.66666667,  1.25      ,  0.25      ,\n",
       "        0.5       ,  2.25      ,  2.        ,  1.        ,  5.66666667,\n",
       "        0.33333333,  0.        ,  1.        ,  0.75      ,  0.5       ,\n",
       "        0.        ,  0.        ,  0.        ,  1.66666667,  4.33333333,\n",
       "        1.        ,  0.25      ,  0.        ,  0.        ,  1.        ,\n",
       "        0.33333333,  1.        ,  1.        ,  1.        ,  8.66666667,\n",
       "        0.25      ,  0.33333333,  0.        ,  0.        ,  0.        ,\n",
       "        0.5       ,  1.5       ,  1.        ,  0.5       ,  0.        ,\n",
       "        0.        ,  0.        ,  0.5       ,  7.66666667,  0.5       ,\n",
       "        5.33333333,  0.75      ,  0.33333333,  0.66666667,  1.5       ,\n",
       "        1.        ,  1.        ,  1.        ,  2.5       ,  0.33333333,\n",
       "        0.        ,  1.33333333,  0.        ,  0.5       ,  4.        ,\n",
       "        2.        ,  0.        ,  2.        ,  0.        ,  0.        ,\n",
       "        2.        ,  0.        ,  8.66666667,  0.33333333,  0.75      ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  6.        ,\n",
       "        0.66666667,  1.33333333,  2.        ,  0.        ,  2.        ,\n",
       "        8.33333333,  0.        ,  2.        ,  2.25      ,  0.        ,\n",
       "        3.        ,  0.        ,  0.        ,  0.5       ,  1.25      ,\n",
       "        0.        ,  0.        ,  0.        ,  2.        ,  3.25      ,\n",
       "        1.33333333,  2.5       ,  2.33333333,  4.5       ,  2.33333333,\n",
       "        2.        ,  2.66666667,  6.66666667,  4.        ,  0.        ,\n",
       "        1.5       ,  0.        ,  1.        ,  2.33333333,  3.        ,\n",
       "        0.        ,  2.33333333,  3.        ,  0.33333333,  1.33333333,\n",
       "        4.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  1.        ,  0.        ,  7.        ,  0.5       ,\n",
       "        0.25      ,  2.33333333,  1.66666667,  4.66666667,  0.75      ,\n",
       "        0.        ,  0.        ,  2.75      ,  4.        ,  4.5       ,\n",
       "        2.66666667,  0.        ,  0.        ,  0.25      ,  1.25      ,\n",
       "        3.25      ,  2.66666667,  1.5       ,  3.5       ,  3.        ,\n",
       "        1.66666667,  1.        ,  1.5       ,  0.        ,  0.        ,\n",
       "        1.5       ,  4.5       ,  1.        ,  0.        ,  0.        ,\n",
       "        0.        ,  2.        ,  0.        ,  5.5       ,  0.66666667,\n",
       "        1.5       ,  0.66666667,  0.        ,  4.66666667,  4.        ,\n",
       "        0.        ,  0.        ,  1.        ,  0.        ,  5.33333333,\n",
       "        4.        ,  1.        ,  0.        ,  0.        ,  2.75      ,\n",
       "        0.        ,  2.25      ,  0.        ,  1.33333333,  1.        ,\n",
       "        0.        ,  0.66666667,  2.        ,  2.5       ,  0.75      ,\n",
       "        7.        ,  0.        ,  0.        ,  0.5       ,  5.66666667,\n",
       "        0.        ,  0.        ,  3.25      ,  1.33333333,  3.5       ,\n",
       "        0.        ,  1.        ,  1.5       ,  1.        ,  4.        ,\n",
       "        9.        ,  1.66666667,  1.33333333,  1.        ,  0.66666667,\n",
       "        1.        ,  0.        ,  1.        ,  4.33333333,  4.75      ,\n",
       "        0.        ,  2.25      ,  0.75      ,  3.33333333,  0.25      ,\n",
       "        0.5       ,  3.33333333,  5.33333333,  0.        ,  0.        ,\n",
       "        0.        ,  2.        ,  5.        ,  0.75      ,  2.        ,\n",
       "        1.66666667,  0.        ,  0.5       ,  0.        ,  0.        ,\n",
       "        0.        ,  0.66666667,  0.        ,  1.        ,  0.75      ,\n",
       "        5.5       ,  0.        ,  1.33333333,  1.33333333,  3.25      ,\n",
       "        0.        ,  7.5       ,  0.33333333,  0.        ,  4.66666667,\n",
       "        0.75      ,  2.        ,  9.        ,  5.5       ,  1.        ,\n",
       "        3.        ,  0.75      ,  0.        ,  0.        ,  2.5       ,\n",
       "        0.        ,  0.25      ,  0.        ,  0.75      ,  0.        ,\n",
       "        4.        ,  2.        ,  2.        ,  0.        ,  0.25      ,\n",
       "        0.66666667,  0.        ,  0.        ,  2.        ,  0.        ,\n",
       "        0.        ,  1.66666667,  1.        ,  0.33333333,  2.        ,\n",
       "        0.75      ,  0.        ,  0.75      , 16.66666667,  1.75      ,\n",
       "        0.        ,  1.        ,  0.        ,  0.5       ,  1.5       ,\n",
       "        5.        ,  0.        ,  1.25      ,  4.        ,  0.5       ,\n",
       "        1.        ,  0.        ,  0.66666667,  0.        ,  7.75      ,\n",
       "        1.75      ,  1.        ,  1.5       ,  1.25      ,  1.        ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ,  1.66666667,\n",
       "        1.        ,  0.        ,  1.        ,  3.25      ,  1.33333333,\n",
       "        6.        ,  0.        ,  2.5       ,  1.25      ,  2.5       ,\n",
       "        0.5       ,  2.33333333,  0.        ,  0.        ,  0.        ,\n",
       "        0.        ,  3.        ,  1.33333333,  0.        ,  0.5       ,\n",
       "        0.        ,  3.        ,  3.5       ,  1.33333333,  4.33333333,\n",
       "        1.5       ,  5.5       ,  2.5       , 12.        ,  0.        ,\n",
       "        0.        ,  3.66666667,  0.75      ,  0.        ,  0.        ,\n",
       "        0.        ,  2.33333333,  0.5       ,  1.75      ,  5.        ,\n",
       "        1.        ,  0.5       ,  0.75      ,  0.5       ,  2.        ,\n",
       "        0.        ,  0.        ,  1.        ,  0.33333333,  0.        ,\n",
       "        0.        ,  0.66666667,  2.        ,  0.        ,  0.        ,\n",
       "        1.25      ,  9.        ,  0.5       ,  1.5       ,  0.5       ,\n",
       "        1.        ,  0.        ,  1.        ,  0.25      ,  0.        ,\n",
       "        1.75      ,  3.33333333,  0.        ,  1.        ,  0.25      ,\n",
       "        0.        ,  0.66666667,  3.33333333,  0.        ,  0.33333333,\n",
       "        1.25      ,  3.5       ,  0.        ,  1.75      ,  0.        ,\n",
       "        0.25      ,  9.5       ,  0.        ,  0.        ,  0.25      ,\n",
       "        4.66666667,  0.33333333,  0.        ,  2.        ,  5.75      ,\n",
       "        0.        ,  2.75      ,  0.        ,  4.33333333,  0.        ,\n",
       "        1.25      ,  3.        ,  0.        ,  0.        ,  0.66666667,\n",
       "        3.        ,  1.        ,  2.33333333,  0.        ,  3.66666667,\n",
       "        0.25      ,  0.        ,  0.        ,  1.66666667,  2.        ,\n",
       "        4.66666667,  1.66666667,  2.        ,  0.        ,  0.        ,\n",
       "        2.5       ,  0.33333333,  2.25      ,  1.        ,  3.33333333,\n",
       "        2.5       , 10.33333333,  2.33333333,  0.        ,  1.5       ,\n",
       "        1.        ,  1.        ,  1.66666667,  0.        ,  5.        ,\n",
       "        2.66666667,  0.        ,  0.        ,  1.        ,  0.33333333])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_differences = []\n",
    "for idx, element in enumerate(arr):\n",
    "    choices = element[\"choices\"]\n",
    "    dists_length = []\n",
    "    for choice in choices:\n",
    "        if choice[\"type\"] == \"correct answer\":\n",
    "            ans = choice[\"text\"]\n",
    "            ans_length = count_words(ans)\n",
    "        if choice[\"type\"] == \"distractor\":\n",
    "            dist = choice[\"text\"]\n",
    "            dists_length.append(count_words(dist))\n",
    "    \n",
    "    arr_diff = np.array([abs(ans_length-x) for x in dists_length])\n",
    "    diff = np.mean(arr_diff)\n",
    "    len_differences.append(diff)\n",
    "\n",
    "len_differences = np.array(len_differences)\n",
    "len_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.666666666666668"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_diff = np.max(len_differences)\n",
    "max_length_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6901197604790419\n",
      "2.284262421295633\n"
     ]
    }
   ],
   "source": [
    "diff_mean = np.mean(len_differences)\n",
    "diff_std = np.std(len_differences)\n",
    "print(diff_mean)\n",
    "print(diff_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.69 +- 2.28'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict[\"|Len(A) - Len(D)|\"] = f\"{diff_mean:0.2f} +- {diff_std:0.2f}\"\n",
    "final_dict[\"Max(|Len(A) - Len(D)|)\"] = max_length_diff\n",
    "final_dict[\"|Len(A) - Len(D)|\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "# of texts                            810\n",
       "# of MCQs                             835\n",
       "# of D                       3.16 +- 0.74\n",
       "Len(Text)                 158.21 +- 54.86\n",
       "Max(Text)                           453.0\n",
       "Len(A)                       4.36 +- 4.49\n",
       "Max(A)                               26.0\n",
       "Len(D)                       4.59 +- 4.97\n",
       "Max(D)                                 43\n",
       "|Len(A) - Len(D)|            1.69 +- 2.28\n",
       "Max(|Len(A) - Len(D)|)          16.666667\n",
       "Name: training, dtype: object"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.Series(final_dict, name=data_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(file_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "id2223",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
